{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/model\")\n",
    "import clip\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "from model.aliproduct_model import ALIPRODUCT_CLIP\n",
    "from model.aliproduct_blip_model import ALIPRODUCT_BLIP\n",
    "from model.dataset import ALIPRODUCT_DATASET,prepare_data\n",
    "from model.CONFIG import CONFIG\n",
    "import faiss\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''Edit this to specify checkpoints of models you want to test \n",
    "defined as key value pair of {\"checpoint name/identifier:\"full path to checkpoint\"}'''\n",
    "\n",
    "checkpoints = {\"base\":\"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_retrieval_coco.pth\",\n",
    "\"epoch_1\":\"/home/ubuntu/Desktop/base_3_itm/base_3rd_e_1.pth\",\n",
    "\"epoch_2\":\"/home/ubuntu/Desktop/base_3_itm/base_3rd_e_2.pth\",\n",
    "\"epoch_3\":\"/home/ubuntu/Desktop/base_3_itm/base_3rd_e_3.pth\",\n",
    "\"epoch_4\":\"/home/ubuntu/Desktop/base_3_itm/base_3rd_e_4.pth\",\n",
    "\"epoch_5\":\"/home/ubuntu/Desktop/base_3_itm/base_3rd_e_5.pth\"}\n",
    "\n",
    "#Edit this to specify the augmented/original captions you want to test the model checkpoints on \n",
    "caption_to_test =  [\"caption\"]\n",
    "\n",
    "\n",
    "#path to validation data after preporcessing into csv file format \n",
    "dataframe_path = \"/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/data/val_data_prompt_clean.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 384\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize((image_size,image_size),interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "        ]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_feature(caption_col,clip_model):\n",
    "    test_loader,df = prepare_data(\"/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/data/val_data_prompt_clean.csv\",\n",
    "    CONFIG.test_image_data_dir,CONFIG.test_image_data_folder\n",
    "    ,CONFIG.test_image_col,caption_col,160,preprocess,CONFIG.global_random_state,test=True,tokenize=False)\n",
    "    trainer = Trainer(gpus=1)\n",
    "    pred = trainer.predict(clip_model,test_loader)\n",
    "    full_pred = tuple(map(torch.concat, zip(*pred)))\n",
    "    image_embed,text_embed = full_pred\n",
    "    # print(image_embed.size())\n",
    "    # print(text_embed.size())\n",
    "    faiss_index = faiss.IndexFlatIP(256)\n",
    "    print(image_embed.numpy().astype(np.float32).shape)\n",
    "    faiss_index.add(image_embed.numpy().astype(np.float32))\n",
    "    top5_k_e,top5_k_y_pred = faiss_index.search(text_embed.numpy().astype(np.float32),5)\n",
    "    top10_k_e,top10_k_y_pred = faiss_index.search(text_embed.numpy().astype(np.float32),10)\n",
    "    top5_preds = np.array([1 if y_true in y_pred else 0 for y_true,y_pred in zip(df.index.values,top5_k_y_pred)])\n",
    "    print(caption_col,\"num correct pred\",sum(top5_preds))\n",
    "    top10_preds = np.array([1 if y_true in y_pred else 0 for y_true,y_pred in zip(df.index.values,top10_k_y_pred)])\n",
    "    print(caption_col,\"num correct pred\",sum(top10_preds))\n",
    "    top5_acc = top5_preds[top5_preds ==1].shape[0] / top5_preds.shape[0]\n",
    "    top10_acc = top10_preds[top10_preds ==1].shape[0] / top10_preds.shape[0]\n",
    "    return top5_acc,top10_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_retrieval_coco.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [18:32<00:00,  3.55s/it]\n",
      "(50000, 256)\n",
      "caption num correct pred 6806\n",
      "caption num correct pred 9587\n",
      "load checkpoint from /home/ubuntu/Desktop/base_3_itm/base_3rd_e_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [18:32<00:00,  3.55s/it]\n",
      "(50000, 256)\n",
      "caption num correct pred 22711\n",
      "caption num correct pred 29021\n",
      "load checkpoint from /home/ubuntu/Desktop/base_3_itm/base_3rd_e_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [18:31<00:00,  3.55s/it]\n",
      "(50000, 256)\n",
      "caption num correct pred 23462\n",
      "caption num correct pred 29989\n",
      "load checkpoint from /home/ubuntu/Desktop/base_3_itm/base_3rd_e_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [18:59<00:00,  3.64s/it]\n",
      "(50000, 256)\n",
      "caption num correct pred 24159\n",
      "caption num correct pred 30524\n",
      "load checkpoint from /home/ubuntu/Desktop/base_3_itm/base_3rd_e_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [18:56<00:00,  3.63s/it]\n",
      "(50000, 256)\n",
      "caption num correct pred 24812\n",
      "caption num correct pred 31197\n",
      "load checkpoint from /home/ubuntu/Desktop/base_3_itm/base_3rd_e_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [18:52<00:00,  3.62s/it]\n",
      "(50000, 256)\n",
      "caption num correct pred 25424\n",
      "caption num correct pred 31777\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top5_acc_preds = []\n",
    "top10_acc_preds = []\n",
    "captions_tested = []\n",
    "for cap in caption_to_test:\n",
    "    for checkpoint in checkpoints.keys():\n",
    "        clip_model =ALIPRODUCT_BLIP(checkpoints[checkpoint],image_size)\n",
    "        top5_acc,top10_acc = test_feature(caption_to_test,clip_model)\n",
    "        top5_acc_preds.append(top5_acc)\n",
    "        top10_acc_preds.append(top10_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = {\"model_checkpoint\":checkpoints.keys(),\"top_5\":top5_acc_preds,\"top_10\":top10_acc_preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13612, 0.45422, 0.46924, 0.48318, 0.49624, 0.50848]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_acc_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_checkpoint</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>0.13612</td>\n",
       "      <td>0.19174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>epoch_1</td>\n",
       "      <td>0.45422</td>\n",
       "      <td>0.58042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>epoch_2</td>\n",
       "      <td>0.46924</td>\n",
       "      <td>0.59978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>epoch_3</td>\n",
       "      <td>0.48318</td>\n",
       "      <td>0.61048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>epoch_4</td>\n",
       "      <td>0.49624</td>\n",
       "      <td>0.62394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>epoch_5</td>\n",
       "      <td>0.50848</td>\n",
       "      <td>0.63554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_checkpoint    top_5   top_10\n",
       "0             base  0.13612  0.19174\n",
       "1          epoch_1  0.45422  0.58042\n",
       "2          epoch_2  0.46924  0.59978\n",
       "3          epoch_3  0.48318  0.61048\n",
       "4          epoch_4  0.49624  0.62394\n",
       "5          epoch_5  0.50848  0.63554"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "caf1c2fcf97217de91eafa76b907d50f9ea378f5ffbee7f571142d119bb6a771"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
