{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file path to where you store your train csv filein your machine if you do not have this file run aliproduct_cvpr_eda_2022.ipynb to generate the base csv file \n",
    "train_csv_path = \"/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/data/train_data_v6_base.csv\"\n",
    "\n",
    "#file path to where you store your validation csv file in your machine if you do not have this file run aliproduct_cvpr_eda_2022.ipynb to generate the base csv file \n",
    "val_csv_path = \"/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/data/val_data_map.csv\"\n",
    "\n",
    "'''column name in your train csv file that contains the file path for each image \n",
    "e.g train_text_img_pairs_{i}/train_text_img_pairs_{i}_compressed/  or train_text_img_pairs_{i}_compressed/ \n",
    "where i denotes the file number from 1-9 in the aliproduct dataset''' \n",
    "\n",
    "train_images_folder_col = \"image_reletive_folder\"\n",
    "\n",
    "\n",
    "#name of folder that your validation images are stored  \n",
    "val_images_folder = \"val_imgs\"\n",
    "\n",
    "\n",
    "\n",
    "'''ONLY FOR PRETRAINING: column name in your train csv file that contains the file path for each image \n",
    "e.g /home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/train_text_img_pairs_{i}/train_text_img_pairs_{i}_compressed/image_1.jpg  \n",
    "or /home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/train_text_img_pairs_{i}_compressed/image_1.jpg \n",
    "where i denotes the file number from 1-9 in the aliproduct dataset''' \n",
    "train_images_full_path_col = \"full_path\"\n",
    "\n",
    "\n",
    "#name of column of train csv that contains the captions\n",
    "train_caption_col_name = \"caption\"\n",
    "\n",
    "#name of column of train csv that contains the the image names witth file extension e.g sample_image_1.jpg,sample_image_2.png,etc\n",
    "train_image_col_name = \"product\"\n",
    "\n",
    "#name of column of validation csv that contains the captions\n",
    "val_caption_col_name = \"caption\"\n",
    "\n",
    "#name of column of validation csv that contains the the image names witth file extension e.g sample_image_1.jpg,sample_image_2.png,etc\n",
    "val_image_col_name = \"product\"\n",
    "\n",
    "\n",
    "#name of output json file for train data \n",
    "train_output_filename = \"../data/aliproduct2_train_ann_v6_large_08.json\"\n",
    "\n",
    "#name of output json file for validation data \n",
    "val_output_filename = \"../data/aliproduct2_val_ann.json\"\n",
    "\n",
    "#name of output json file for training data used only for pretraining  \n",
    "pretrain_output_filename = \"../data/aliproduct2_pretrain_ann_v2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"image\"] = train_df[train_images_folder_col] + train_df[train_image_col_name]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"image_id\"] = \"aliproduct2_train_\" +  train_df.index.map(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_caption = train_df[train_caption_col_name].values\n",
    "train_images = train_df[\"image\"].values\n",
    "train_image_id = train_df[\"image_id\"].values\n",
    "train_images_pretrain = train_df[train_images_full_path_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ann = [{\"caption\":cap,\"image\":img,\"image_id\":id} for cap,img,id in zip(train_caption,train_images,train_image_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ann_pretrain = [{\"caption\":cap,\"image\":img,\"image_id\":id} for cap,img,id in zip(train_caption,train_images_pretrain,train_image_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = train_output_filename\n",
    "file = open(filename,\"w\")\n",
    "json.dump(train_ann,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = pretrain_output_filename\n",
    "file = open(filename,\"w\")\n",
    "json.dump(train_ann_pretrain,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(val_csv_path)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[\"image\"] = f\"{val_images_folder}/\"+val_df[val_image_col_name]\n",
    "val_df[\"image_id\"] = val_df.index.map(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_caption = val_df[val_caption_col_name].values\n",
    "val_images = val_df[\"image\"].values\n",
    "val_image_id = val_df[\"image_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ann = [{\"caption\":cap,\"image\":img,\"image_id\":id} for cap,img,id in zip(val_caption,val_images,val_image_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = val_output_filename\n",
    "file = open(filename,\"w\")\n",
    "json.dump(val_ann,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "caf1c2fcf97217de91eafa76b907d50f9ea378f5ffbee7f571142d119bb6a771"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
