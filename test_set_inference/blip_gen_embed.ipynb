{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..', '..', '..', '..', '..', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/test_set_inference', '/home/ubuntu/anaconda3/lib/python39.zip', '/home/ubuntu/anaconda3/lib/python3.9', '/home/ubuntu/anaconda3/lib/python3.9/lib-dynload', '', '/home/ubuntu/anaconda3/lib/python3.9/site-packages', '/home/ubuntu/anaconda3/lib/python3.9/site-packages/locket-0.2.1-py3.9.egg', '/home/ubuntu/anaconda3/lib/python3.9/site-packages/IPython/extensions', '/home/ubuntu/.ipython', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/tmp/tmpczg6hdqe', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model']\n",
      "['..', '..', '..', '..', '..', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/test_set_inference', '/home/ubuntu/anaconda3/lib/python39.zip', '/home/ubuntu/anaconda3/lib/python3.9', '/home/ubuntu/anaconda3/lib/python3.9/lib-dynload', '', '/home/ubuntu/anaconda3/lib/python3.9/site-packages', '/home/ubuntu/anaconda3/lib/python3.9/site-packages/locket-0.2.1-py3.9.egg', '/home/ubuntu/anaconda3/lib/python3.9/site-packages/IPython/extensions', '/home/ubuntu/.ipython', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/tmp/tmpczg6hdqe', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "print(sys.path)\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/model\")\n",
    "print(sys.path)\n",
    "import clip\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "from model.aliproduct_model import ALIPRODUCT_CLIP\n",
    "from model.aliproduct_blip_model import ALIPRODUCT_BLIP\n",
    "from model.dataset import ALIPRODUCT_DATASET,prepare_data\n",
    "from model.CONFIG import CONFIG\n",
    "import faiss\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv(\"/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/test_set_inference/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>test_caption</th>\n",
       "      <th>test_imgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>feiyangg/LP Paragraph Style Electric Guitar Ti...</td>\n",
       "      <td>O1CN01r2RqZk1lJ4Sk2ZYaN_!!2200643934797.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Summer Lace White Shorts Pants Female Thin Ant...</td>\n",
       "      <td>O1CN01H0o2pi2HAtGC9rVWa_!!2206736519111.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>High-Quality Export 8MM with Adhesive Cork Cor...</td>\n",
       "      <td>O1CN01qeHW0Z1D3mRPfmNvM_!!161-0-lubanu.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LED Ceiling Living Room Bedroom Corridor Corri...</td>\n",
       "      <td>O1CN01phQoOe25ljjN1lpLO_!!3082327567.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Disposable Cotton Cotton Female Thin Water Fac...</td>\n",
       "      <td>O1CN01Dzpgpr2FxJsUzqAdE_!!2963188946.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       test_caption  \\\n",
       "0           0  feiyangg/LP Paragraph Style Electric Guitar Ti...   \n",
       "1           1  Summer Lace White Shorts Pants Female Thin Ant...   \n",
       "2           2  High-Quality Export 8MM with Adhesive Cork Cor...   \n",
       "3           3  LED Ceiling Living Room Bedroom Corridor Corri...   \n",
       "4           4  Disposable Cotton Cotton Female Thin Water Fac...   \n",
       "\n",
       "                                     test_imgs  \n",
       "0  O1CN01r2RqZk1lJ4Sk2ZYaN_!!2200643934797.jpg  \n",
       "1  O1CN01H0o2pi2HAtGC9rVWa_!!2206736519111.jpg  \n",
       "2   O1CN01qeHW0Z1D3mRPfmNvM_!!161-0-lubanu.jpg  \n",
       "3     O1CN01phQoOe25ljjN1lpLO_!!3082327567.jpg  \n",
       "4     O1CN01Dzpgpr2FxJsUzqAdE_!!2963188946.jpg  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>test_caption</th>\n",
       "      <th>test_imgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>this data is null</td>\n",
       "      <td>TB1gz7TgipE_u4jSZKbq6zCUVXa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>this data is null</td>\n",
       "      <td>O1CN018DjGnX1QeV9jOECs2_!!3432982001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>this data is null</td>\n",
       "      <td>O1CN019QiqKF1MnQTM0gdna_!!2211026631479.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>this data is null</td>\n",
       "      <td>TB1yui5VoT1gK0jSZFrq6ANCXXa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>this data is null</td>\n",
       "      <td>O1CN01cxGSZT26bwr7f1io2_!!2707697681.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       test_caption  \\\n",
       "49995       49995  this data is null   \n",
       "49996       49996  this data is null   \n",
       "49997       49997  this data is null   \n",
       "49998       49998  this data is null   \n",
       "49999       49999  this data is null   \n",
       "\n",
       "                                         test_imgs  \n",
       "49995                  TB1gz7TgipE_u4jSZKbq6zCUVXa  \n",
       "49996     O1CN018DjGnX1QeV9jOECs2_!!3432982001.jpg  \n",
       "49997  O1CN019QiqKF1MnQTM0gdna_!!2211026631479.jpg  \n",
       "49998                  TB1yui5VoT1gK0jSZFrq6ANCXXa  \n",
       "49999     O1CN01cxGSZT26bwr7f1io2_!!2707697681.jpg  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_to_test =  [c for c in clean_df.columns.values if \"caption\" in c] + [c for c in clean_df.columns.values if \"step\" in c]\n",
    "col_to_test =  \"test_caption\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 384\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize((image_size,image_size),interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "        ]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_embed(caption_col,clip_model):\n",
    "    test_loader,df = prepare_data(\"/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/test_set_inference/test.csv\",\n",
    "    CONFIG.test_image_data_dir,\"test_imgs\"\n",
    "    ,\"test_imgs\",caption_col,160,preprocess,CONFIG.global_random_state,test=True,tokenize=False)\n",
    "    trainer = Trainer(gpus=1)\n",
    "    pred = trainer.predict(clip_model,test_loader)\n",
    "    full_pred = tuple(map(torch.concat, zip(*pred)))\n",
    "    image_embed,text_embed = full_pred\n",
    "\n",
    "    return image_embed,text_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embed(image_embed,text_embed,model_size:str,prefix:str):\n",
    "    img_embed_path = \"./image_embeds\"\n",
    "    txt_embed_path = \"./text_embeds\"\n",
    "    img_embed_filename = f\"img_emded-{model_size}-{prefix}.pkl\"\n",
    "    txt_embed_filename = f\"txt_emded-{model_size}-{prefix}.pkl\"\n",
    "    img_embed_full_path = f\"{img_embed_path}/{img_embed_filename}\"\n",
    "    txt_embed_full_path = f\"{txt_embed_path}/{txt_embed_filename}\"\n",
    "\n",
    "    image_embed_info_dict = {\"model_name\":prefix,\"model_size\":model_size,\"pair_name\":txt_embed_filename,\"embed\":image_embed}\n",
    "    text_embed_info_dict = {\"model_name\":prefix,\"model_size\":model_size,\"pair_name\":img_embed_filename,\"embed\":text_embed}\n",
    "\n",
    "    with open(img_embed_full_path,\"wb\") as file:\n",
    "        print(f\"saving img embed from {prefix} to {img_embed_full_path}\")\n",
    "        pickle.dump(image_embed_info_dict,file)\n",
    "    with open(txt_embed_full_path,\"wb\") as file:\n",
    "        print(f\"saving txt embed from {prefix} to {txt_embed_full_path}\")\n",
    "        pickle.dump(text_embed_info_dict,file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting embeddings from base_all_e_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from /home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model/BLIP/output/save_checkpoint_7_thu.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [18:39<00:00,  3.58s/it]\n",
      "saving img embed from base_all_e_7 to ./image_embeds/img_emded-base-base_all_e_7.pkl\n",
      "saving txt embed from base_all_e_7 to ./text_embeds/txt_emded-base-base_all_e_7.pkl\n",
      "extracting embeddings from base_1st_e_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from /home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model/BLIP/output/Retrieval_aliproduct2_filtered/save_checkpoint_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [18:43<00:00,  3.59s/it]\n",
      "saving img embed from base_1st_e_5 to ./image_embeds/img_emded-base-base_1st_e_5.pkl\n",
      "saving txt embed from base_1st_e_5 to ./text_embeds/txt_emded-base-base_1st_e_5.pkl\n",
      "extracting embeddings from base_2nd_e_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from /home/ubuntu/Desktop/base_2nd/base_2nd_e_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [18:43<00:00,  3.59s/it]\n",
      "saving img embed from base_2nd_e_5 to ./image_embeds/img_emded-base-base_2nd_e_5.pkl\n",
      "saving txt embed from base_2nd_e_5 to ./text_embeds/txt_emded-base-base_2nd_e_5.pkl\n",
      "extracting embeddings from base_3rd_e_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from /home/ubuntu/Desktop/base_3_itm/base_3rd_e_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [18:41<00:00,  3.58s/it]\n",
      "saving img embed from base_3rd_e_5 to ./image_embeds/img_emded-base-base_3rd_e_5.pkl\n",
      "saving txt embed from base_3rd_e_5 to ./text_embeds/txt_emded-base-base_3rd_e_5.pkl\n",
      "extracting embeddings from large_all_e_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from /home/ubuntu/Desktop/Retrieval_aliproduct2_blip_large/save_checkpoint_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [52:20<00:00, 10.04s/it]\n",
      "saving img embed from large_all_e_9 to ./image_embeds/img_emded-large-large_all_e_9.pkl\n",
      "saving txt embed from large_all_e_9 to ./text_embeds/txt_emded-large-large_all_e_9.pkl\n",
      "extracting embeddings from large_v1_e_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from /home/ubuntu/Desktop/large_v4/save_checkpoint_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 313/313 [52:20<00:00, 10.03s/it]\n",
      "saving img embed from large_v1_e_5 to ./image_embeds/img_emded-large-large_v1_e_5.pkl\n",
      "saving txt embed from large_v1_e_5 to ./text_embeds/txt_emded-large-large_v1_e_5.pkl\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {\"path\":\"/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model/BLIP/output/save_checkpoint_7_thu.pth\",\n",
    "    \"model_size\":\"base\",\"model_name\":\"base_all_e_7\"},\n",
    "    {\"path\":\"/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model/BLIP/output/Retrieval_aliproduct2_filtered/save_checkpoint_4.pth\",\n",
    "    \"model_size\":\"base\",\"model_name\":\"base_1st_e_5\"},\n",
    "    {\"path\":\"/home/ubuntu/Desktop/base_2nd/base_2nd_e_5.pth\",\"model_size\":\"base\",\"model_name\":\"base_2nd_e_5\"},\n",
    "    {\"path\":\"/home/ubuntu/Desktop/base_3_itm/base_3rd_e_5.pth\",\n",
    "    \"model_size\":\"base\",\"model_name\":\"base_3rd_e_5\"},\n",
    "     {\"path\":\"/home/ubuntu/Desktop/Retrieval_aliproduct2_blip_large/save_checkpoint_8.pth\",\"model_size\":\"large\",\"model_name\":\"large_all_e_9\"},\n",
    "    {\"path\":\"/home/ubuntu/Desktop/large_v4/save_checkpoint_4.pth\",\"model_size\":\"large\",\"model_name\":\"large_v1_e_5\"},\n",
    "    ]\n",
    "\n",
    "for model in models:\n",
    "    print(f\"extracting embeddings from \"+model[\"model_name\"])\n",
    "    clip_model =ALIPRODUCT_BLIP(model[\"path\"],image_size,vit=model[\"model_size\"])\n",
    "    image_embed,text_embed = gen_embed(col_to_test,clip_model)\n",
    "    text_embed_no_null = text_embed[0:20000]\n",
    "    save_embed(image_embed,text_embed_no_null,model[\"model_size\"],model[\"model_name\"])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "caf1c2fcf97217de91eafa76b907d50f9ea378f5ffbee7f571142d119bb6a771"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
