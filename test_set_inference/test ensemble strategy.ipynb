{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..', '..', '..', '..', '..', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/test_set_inference', '/home/ubuntu/anaconda3/lib/python39.zip', '/home/ubuntu/anaconda3/lib/python3.9', '/home/ubuntu/anaconda3/lib/python3.9/lib-dynload', '', '/home/ubuntu/anaconda3/lib/python3.9/site-packages', '/home/ubuntu/anaconda3/lib/python3.9/site-packages/locket-0.2.1-py3.9.egg', '/home/ubuntu/anaconda3/lib/python3.9/site-packages/IPython/extensions', '/home/ubuntu/.ipython', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/tmp/tmp9pbbnyjp', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model']\n",
      "['..', '..', '..', '..', '..', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/test_set_inference', '/home/ubuntu/anaconda3/lib/python39.zip', '/home/ubuntu/anaconda3/lib/python3.9', '/home/ubuntu/anaconda3/lib/python3.9/lib-dynload', '', '/home/ubuntu/anaconda3/lib/python3.9/site-packages', '/home/ubuntu/anaconda3/lib/python3.9/site-packages/locket-0.2.1-py3.9.egg', '/home/ubuntu/anaconda3/lib/python3.9/site-packages/IPython/extensions', '/home/ubuntu/.ipython', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/tmp/tmp9pbbnyjp', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "print(sys.path)\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/model\")\n",
    "print(sys.path)\n",
    "import clip\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "from model.aliproduct_model import ALIPRODUCT_CLIP\n",
    "from model.aliproduct_blip_model import ALIPRODUCT_BLIP\n",
    "from model.dataset import ALIPRODUCT_DATASET,prepare_data\n",
    "from model.CONFIG import CONFIG\n",
    "import faiss\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "import json\n",
    "from autofaiss import build_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>product</th>\n",
       "      <th>label</th>\n",
       "      <th>step_1_lower</th>\n",
       "      <th>step_2_no_sp_char</th>\n",
       "      <th>step_3_no_stop</th>\n",
       "      <th>step_4_no_num</th>\n",
       "      <th>step_5_no_dupe</th>\n",
       "      <th>step_6_no_len_1_token</th>\n",
       "      <th>caption_crop_first_70%</th>\n",
       "      <th>caption_crop_last_70%</th>\n",
       "      <th>caption_crop_middle_70%</th>\n",
       "      <th>captions_cn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanabata Valentine's Day Shenzhen Bao'an M Nan...</td>\n",
       "      <td>O1CN01cSoTwD1spJos7ZSF6_!!0-item_pic.jpg</td>\n",
       "      <td>32820</td>\n",
       "      <td>tanabata valentine's day shenzhen bao'an m nan...</td>\n",
       "      <td>tanabata valentines day shenzhen baoan m nansh...</td>\n",
       "      <td>tanabata valentines day shenzhen baoan nanshan...</td>\n",
       "      <td>tanabata valentines day shenzhen baoan nanshan...</td>\n",
       "      <td>luohu arrangement valentines decorative chest ...</td>\n",
       "      <td>arrangement chest valentines decorative nansha...</td>\n",
       "      <td>Tanabata Valentine's Day Shenzhen Bao'an M Nan...</td>\n",
       "      <td>M Nanshan Futian Luohu Car Decorative Flowers ...</td>\n",
       "      <td>Shenzhen Bao'an M Nanshan Futian Luohu Car Dec...</td>\n",
       "      <td>塔那巴塔情人节 清心宝安 南山福田罗虎 汽车装饰花花花花花花 胸衣布置安排</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Children's Toys Little Girl over 6 Years Old G...</td>\n",
       "      <td>O1CN01iI5sGv1vIkV5dfICu_!!0-item_pic.jpg</td>\n",
       "      <td>8326</td>\n",
       "      <td>children's toys little girl over 6 years old g...</td>\n",
       "      <td>childrens toys little girl over 6 years old gi...</td>\n",
       "      <td>childrens toys little girl 6 years old girls 3...</td>\n",
       "      <td>childrens toys little girl years old girls boy...</td>\n",
       "      <td>years childrens little old boys baby gift chil...</td>\n",
       "      <td>years childrens little old boys baby gift chil...</td>\n",
       "      <td>Children's Toys Little Girl over 6 Years Old G...</td>\n",
       "      <td>Old Girls 3-9 Boys 7 Students I Day Gift 10 Ch...</td>\n",
       "      <td>over 6 Years Old Girls 3-9 Boys 7 Students I D...</td>\n",
       "      <td>6岁以上的儿童玩具小女孩 3-9 男孩 7 学生I日 学生I日 10 儿童8 婴儿4 拼图</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sm qing qu Alternative Sex between Men and Wom...</td>\n",
       "      <td>O1CN01xnnyaz248W0n5le2q_!!131027346.jpg</td>\n",
       "      <td>47598</td>\n",
       "      <td>sm qing qu alternative sex between men and wom...</td>\n",
       "      <td>sm qing qu alternative sex between men and wom...</td>\n",
       "      <td>sm qing qu alternative sex men women metal tai...</td>\n",
       "      <td>sm qing qu alternative sex men women metal tai...</td>\n",
       "      <td>tail men fox ting alternative qu sex sai women...</td>\n",
       "      <td>tail men fox metal alternative qu sex sai wome...</td>\n",
       "      <td>sm qing qu Alternative Sex between Men and Wom...</td>\n",
       "      <td>between Men and Women with Metal Tail Fox Tail...</td>\n",
       "      <td>Alternative Sex between Men and Women with Met...</td>\n",
       "      <td>使用金属尾狐尾巴的男女替代性行为</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Traditional Chinese Painting Burnin' Up Yingke...</td>\n",
       "      <td>O1CN01lfHuuA1D3K2MEM63p_!!160-0-lubanu.jpg</td>\n",
       "      <td>36608</td>\n",
       "      <td>traditional chinese painting burnin' up yingke...</td>\n",
       "      <td>traditional chinese painting burnin up yingkes...</td>\n",
       "      <td>traditional chinese painting burnin yingkesong...</td>\n",
       "      <td>traditional chinese painting burnin yingkesong...</td>\n",
       "      <td>lucky patron paintings decorative traditional ...</td>\n",
       "      <td>lucky patron paintings decorative traditional ...</td>\n",
       "      <td>Traditional Chinese Painting Burnin' Up Yingke...</td>\n",
       "      <td>Yingkesong Landscape Painting Patron Living Ro...</td>\n",
       "      <td>Burnin' Up Yingkesong Landscape Painting Patro...</td>\n",
       "      <td>中华传统绘画烧在延克松露地绘画主办人 客厅绘画老板办公室 幸运装饰墙壁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgnace Lee Men's Jeans Thick Section Distresse...</td>\n",
       "      <td>TB23FV3afBNTKJjy0FdXXcPpVXa_!!1944606990.jpg</td>\n",
       "      <td>45566</td>\n",
       "      <td>lgnace lee men's jeans thick section distresse...</td>\n",
       "      <td>lgnace lee mens jeans thick section distressed...</td>\n",
       "      <td>lgnace lee mens jeans thick section distressed...</td>\n",
       "      <td>lgnace lee mens jeans thick section distressed...</td>\n",
       "      <td>lee jeans mens tide brand slacksmusic lgnace t...</td>\n",
       "      <td>lee jeans mens tide brand slacksmusic lgnace t...</td>\n",
       "      <td>lgnace Lee Men's Jeans Thick Section Distresse...</td>\n",
       "      <td>Section Distressed Straight Youth Autumn Tide ...</td>\n",
       "      <td>Men's Jeans Thick Section Distressed Straight ...</td>\n",
       "      <td>Lgnace Lee Lee Men的Jeans Thick分会受困于直立青年 秋秋潮的B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption  \\\n",
       "0  Tanabata Valentine's Day Shenzhen Bao'an M Nan...   \n",
       "1  Children's Toys Little Girl over 6 Years Old G...   \n",
       "2  sm qing qu Alternative Sex between Men and Wom...   \n",
       "3  Traditional Chinese Painting Burnin' Up Yingke...   \n",
       "4  lgnace Lee Men's Jeans Thick Section Distresse...   \n",
       "\n",
       "                                        product  label  \\\n",
       "0      O1CN01cSoTwD1spJos7ZSF6_!!0-item_pic.jpg  32820   \n",
       "1      O1CN01iI5sGv1vIkV5dfICu_!!0-item_pic.jpg   8326   \n",
       "2       O1CN01xnnyaz248W0n5le2q_!!131027346.jpg  47598   \n",
       "3    O1CN01lfHuuA1D3K2MEM63p_!!160-0-lubanu.jpg  36608   \n",
       "4  TB23FV3afBNTKJjy0FdXXcPpVXa_!!1944606990.jpg  45566   \n",
       "\n",
       "                                        step_1_lower  \\\n",
       "0  tanabata valentine's day shenzhen bao'an m nan...   \n",
       "1  children's toys little girl over 6 years old g...   \n",
       "2  sm qing qu alternative sex between men and wom...   \n",
       "3  traditional chinese painting burnin' up yingke...   \n",
       "4  lgnace lee men's jeans thick section distresse...   \n",
       "\n",
       "                                   step_2_no_sp_char  \\\n",
       "0  tanabata valentines day shenzhen baoan m nansh...   \n",
       "1  childrens toys little girl over 6 years old gi...   \n",
       "2  sm qing qu alternative sex between men and wom...   \n",
       "3  traditional chinese painting burnin up yingkes...   \n",
       "4  lgnace lee mens jeans thick section distressed...   \n",
       "\n",
       "                                      step_3_no_stop  \\\n",
       "0  tanabata valentines day shenzhen baoan nanshan...   \n",
       "1  childrens toys little girl 6 years old girls 3...   \n",
       "2  sm qing qu alternative sex men women metal tai...   \n",
       "3  traditional chinese painting burnin yingkesong...   \n",
       "4  lgnace lee mens jeans thick section distressed...   \n",
       "\n",
       "                                       step_4_no_num  \\\n",
       "0  tanabata valentines day shenzhen baoan nanshan...   \n",
       "1  childrens toys little girl years old girls boy...   \n",
       "2  sm qing qu alternative sex men women metal tai...   \n",
       "3  traditional chinese painting burnin yingkesong...   \n",
       "4  lgnace lee mens jeans thick section distressed...   \n",
       "\n",
       "                                      step_5_no_dupe  \\\n",
       "0  luohu arrangement valentines decorative chest ...   \n",
       "1  years childrens little old boys baby gift chil...   \n",
       "2  tail men fox ting alternative qu sex sai women...   \n",
       "3  lucky patron paintings decorative traditional ...   \n",
       "4  lee jeans mens tide brand slacksmusic lgnace t...   \n",
       "\n",
       "                               step_6_no_len_1_token  \\\n",
       "0  arrangement chest valentines decorative nansha...   \n",
       "1  years childrens little old boys baby gift chil...   \n",
       "2  tail men fox metal alternative qu sex sai wome...   \n",
       "3  lucky patron paintings decorative traditional ...   \n",
       "4  lee jeans mens tide brand slacksmusic lgnace t...   \n",
       "\n",
       "                              caption_crop_first_70%  \\\n",
       "0  Tanabata Valentine's Day Shenzhen Bao'an M Nan...   \n",
       "1  Children's Toys Little Girl over 6 Years Old G...   \n",
       "2  sm qing qu Alternative Sex between Men and Wom...   \n",
       "3  Traditional Chinese Painting Burnin' Up Yingke...   \n",
       "4  lgnace Lee Men's Jeans Thick Section Distresse...   \n",
       "\n",
       "                               caption_crop_last_70%  \\\n",
       "0  M Nanshan Futian Luohu Car Decorative Flowers ...   \n",
       "1  Old Girls 3-9 Boys 7 Students I Day Gift 10 Ch...   \n",
       "2  between Men and Women with Metal Tail Fox Tail...   \n",
       "3  Yingkesong Landscape Painting Patron Living Ro...   \n",
       "4  Section Distressed Straight Youth Autumn Tide ...   \n",
       "\n",
       "                             caption_crop_middle_70%  \\\n",
       "0  Shenzhen Bao'an M Nanshan Futian Luohu Car Dec...   \n",
       "1  over 6 Years Old Girls 3-9 Boys 7 Students I D...   \n",
       "2  Alternative Sex between Men and Women with Met...   \n",
       "3  Burnin' Up Yingkesong Landscape Painting Patro...   \n",
       "4  Men's Jeans Thick Section Distressed Straight ...   \n",
       "\n",
       "                                         captions_cn  \n",
       "0              塔那巴塔情人节 清心宝安 南山福田罗虎 汽车装饰花花花花花花 胸衣布置安排  \n",
       "1      6岁以上的儿童玩具小女孩 3-9 男孩 7 学生I日 学生I日 10 儿童8 婴儿4 拼图  \n",
       "2                                   使用金属尾狐尾巴的男女替代性行为  \n",
       "3                中华传统绘画烧在延克松露地绘画主办人 客厅绘画老板办公室 幸运装饰墙壁  \n",
       "4   Lgnace Lee Lee Men的Jeans Thick分会受困于直立青年 秋秋潮的B...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.read_csv(\"/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/data/val_data_prompt_clean.csv\")\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embed_path = \"./image_embeds/val_set_embed\"\n",
    "text_embed_path = \"./text_embeds/val_set_embed\"\n",
    "image_embed_files = os.listdir(image_embed_path)\n",
    "text_embed_files = os.listdir(text_embed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:08,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "all_image_embed ={}\n",
    "all_text_embed = {}\n",
    "for i,t in tqdm(zip(image_embed_files,text_embed_files)):\n",
    "    with open(f\"{image_embed_path}/{i}\",\"rb\") as img_file:\n",
    "        img_embed = pickle.load(img_file)\n",
    "        all_image_embed[img_embed[\"model_name\"]] = img_embed[\"embed\"]\n",
    "    with open(f\"{text_embed_path}/{t}\",\"rb\") as txt_file:\n",
    "        txt_embed = pickle.load(txt_file)\n",
    "        all_text_embed[txt_embed[\"model_name\"]] = txt_embed[\"embed\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['large_v2_e_5', 'base_5th_e_5', 'base_all_e_7', 'base_2nd_e_5', 'base_1st_e_5', 'large_v1_e_5', 'base_3rd_e_5', 'base_4th_e_5', 'large_v3_e_1', 'large_all_e_9', 'large_v4_e_1'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_image_embed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['large_v4_e_1', 'large_v2_e_5', 'base_1st_e_5', 'base_3rd_e_5', 'base_2nd_e_5', 'base_all_e_7', 'base_5th_e_5', 'large_all_e_9', 'large_v3_e_1', 'base_4th_e_5', 'large_v1_e_5'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_embed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_to_test = \"large_all_e_9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_to_ensamble = [\"base_1st_e_5\",\"base_2nd_e_5\"]\n",
    "\n",
    "# embed_to_ensamble = list(all_text_embed.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensamble(all_image_embed,all_text_embed,embeds_to_ensamble,ensamble_strategy,all_weights):\n",
    "    ensamsables = {}\n",
    "    img_embed_list = []\n",
    "    text_embed_list = []\n",
    "    all_weights = all_weights\n",
    "    for model_name ,weights in zip(embeds_to_ensamble,range(len(all_weights))):\n",
    "        img_embed_list.append(all_image_embed[model_name]*all_weights[weights])\n",
    "        text_embed_list.append(all_text_embed[model_name]*all_weights[weights])\n",
    "    if len(embeds_to_ensamble) > 1:\n",
    "        if ensamble_strategy ==\"concat\":\n",
    "            ensamsables[\"image\"] = torch.concat(img_embed_list,dim=1)\n",
    "            ensamsables[\"text\"] = torch.concat(text_embed_list,dim=1)\n",
    "        elif ensamble_strategy ==\"avg\":\n",
    "            ensamsables[\"image\"] = torch.mean(torch.stack(img_embed_list),0)\n",
    "            ensamsables[\"text\"] = torch.mean(torch.stack(text_embed_list),0)\n",
    "        else:\n",
    "            ensamsables[\"image\"] = img_embed_list\n",
    "            ensamsables[\"text\"] = text_embed_list\n",
    "        return ensamsables\n",
    "    else:\n",
    "            ensamsables[\"image\"] = img_embed_list[0]\n",
    "            ensamsables[\"text\"] = text_embed_list[0]\n",
    "            return ensamsables\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# test = itertools.combinations(all_text_embed,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_preds(ensamsables,score=False,df=None,use_faiss=True,auto_faiss=False,max_ensamble=False,sharpen_weight = 1):\n",
    "    image_embed = ensamsables[\"image\"]\n",
    "    text_embed = ensamsables[\"text\"]\n",
    "    if use_faiss:\n",
    "        faiss_index = faiss.IndexFlatIP(image_embed.shape[1])\n",
    "        faiss_index.add(image_embed.numpy().astype(np.float32))\n",
    "        top5_k_e,top5_k_y_pred = faiss_index.search(text_embed.numpy().astype(np.float32),5)\n",
    "        top10_k_e,top10_k_y_pred = faiss_index.search(text_embed.numpy().astype(np.float32),10)\n",
    "    elif auto_faiss:\n",
    "        auto_faiss_index,index_infos  = build_index(image_embed.numpy().astype(np.float32), save_on_disk=False)\n",
    "        top5_k_e,top5_k_y_pred = auto_faiss_index.search(text_embed.numpy().astype(np.float32),5)\n",
    "        top10_k_e,top10_k_y_pred = auto_faiss_index.search(text_embed.numpy().astype(np.float32),10)\n",
    "\n",
    "    elif max_ensamble:\n",
    "        all_top10_cosine_sim  =[]\n",
    "        all_top5_cosine_sim  =[]\n",
    "        all_top10_pred_idx  =[]\n",
    "        all_top5_pred_idx  =[]\n",
    "        for text,image in zip(text_embed,image_embed):\n",
    "            faiss_index = faiss.IndexFlatIP(image.shape[1])\n",
    "            faiss_index.add(image.numpy().astype(np.float32))\n",
    "            top5_cosine_sim,top5_pred_idx = faiss_index.search(text.numpy().astype(np.float32),5)\n",
    "            top10_cosine_sim,top10_pred_idx = faiss_index.search(text.numpy().astype(np.float32),10)\n",
    "            all_top10_cosine_sim.append(top10_cosine_sim)\n",
    "            all_top5_cosine_sim.append(top5_cosine_sim) \n",
    "            all_top10_pred_idx.append(top10_pred_idx)\n",
    "            all_top5_pred_idx.append(top5_pred_idx)\n",
    "        all_top10_cosine_sim  = np.concatenate(all_top10_cosine_sim,axis=1)\n",
    "        all_top5_cosine_sim  = np.concatenate(all_top5_cosine_sim,axis=1)\n",
    "        all_top10_pred_idx  = np.concatenate(all_top10_pred_idx,axis=1)\n",
    "        all_top5_pred_idx  = np.concatenate(all_top5_pred_idx,axis=1)\n",
    "        top5_k_y_pred = []\n",
    "        top10_k_y_pred = []\n",
    "        for t5,t10,t5_i,t10_i in zip(all_top5_cosine_sim,all_top10_cosine_sim,all_top5_pred_idx,all_top10_pred_idx):\n",
    "            top5_k_y_pred.append(t5_i[np.argpartition(t5,-5)[-5:]])\n",
    "            top10_k_y_pred.append(t10_i[np.argpartition(t10,-10)[-10:]])\n",
    "        print(top10_k_y_pred)\n",
    "\n",
    "    else:\n",
    "        all_cosine_sim  =[]\n",
    "        all_weights = [0.3,0.5,0.2]\n",
    "        for text,image,w_i in zip(text_embed,image_embed,range(len(all_weights))):\n",
    "            cosine_sim = text @ image.T \n",
    "            all_cosine_sim.append(cosine_sim * all_weights[w_i])\n",
    "            del cosine_sim\n",
    "        # ensamble_cosine_sim = torch.mean(torch.stack(all_cosine_sim),dim=0) \n",
    "        # ensamble_cosine_sim = 1 / torch.mean(1. / (torch.stack(all_cosine_sim)) +0.0001,dim=0) \n",
    "        ensamble_cosine_sim = torch.prod(torch.stack(all_cosine_sim),dim=0) \n",
    "        top5_k_e,top5_k_y_pred = torch.topk(ensamble_cosine_sim,5)\n",
    "        top10_k_e,top10_k_y_pred = torch.topk(ensamble_cosine_sim,10)\n",
    "    if score:\n",
    "            top5_preds = np.array([1 if y_true in y_pred else 0 for y_true,y_pred in zip(df.index.values,top5_k_y_pred)])\n",
    "            top10_preds = np.array([1 if y_true in y_pred else 0 for y_true,y_pred in zip(df.index.values,top10_k_y_pred)])\n",
    "            top5_acc = top5_preds[top5_preds ==1].shape[0] / top5_preds.shape[0]\n",
    "            top10_acc = top10_preds[top10_preds ==1].shape[0] / top10_preds.shape[0]\n",
    "            avg_acc = (top5_acc+top10_acc)/2\n",
    "            return top5_acc,top10_acc,avg_acc\n",
    "    else:\n",
    "        return top5_k_y_pred,top10_k_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:02<00:00,  5.65s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>top_5_acc</th>\n",
       "      <th>top_10_acc</th>\n",
       "      <th>avg_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>large_v4_e_1</td>\n",
       "      <td>0.54818</td>\n",
       "      <td>0.67414</td>\n",
       "      <td>0.61116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large_v2_e_5</td>\n",
       "      <td>0.56708</td>\n",
       "      <td>0.69000</td>\n",
       "      <td>0.62854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base_1st_e_5</td>\n",
       "      <td>0.50582</td>\n",
       "      <td>0.63248</td>\n",
       "      <td>0.56915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base_3rd_e_5</td>\n",
       "      <td>0.50848</td>\n",
       "      <td>0.63554</td>\n",
       "      <td>0.57201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base_2nd_e_5</td>\n",
       "      <td>0.50958</td>\n",
       "      <td>0.63606</td>\n",
       "      <td>0.57282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base_all_e_7</td>\n",
       "      <td>0.48374</td>\n",
       "      <td>0.61216</td>\n",
       "      <td>0.54795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>base_5th_e_5</td>\n",
       "      <td>0.51670</td>\n",
       "      <td>0.64624</td>\n",
       "      <td>0.58147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>large_all_e_9</td>\n",
       "      <td>0.52332</td>\n",
       "      <td>0.64678</td>\n",
       "      <td>0.58505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>large_v3_e_1</td>\n",
       "      <td>0.54694</td>\n",
       "      <td>0.67216</td>\n",
       "      <td>0.60955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base_4th_e_5</td>\n",
       "      <td>0.51768</td>\n",
       "      <td>0.64680</td>\n",
       "      <td>0.58224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>large_v1_e_5</td>\n",
       "      <td>0.54804</td>\n",
       "      <td>0.67272</td>\n",
       "      <td>0.61038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  top_5_acc  top_10_acc  avg_acc\n",
       "0    large_v4_e_1    0.54818     0.67414  0.61116\n",
       "1    large_v2_e_5    0.56708     0.69000  0.62854\n",
       "2    base_1st_e_5    0.50582     0.63248  0.56915\n",
       "3    base_3rd_e_5    0.50848     0.63554  0.57201\n",
       "4    base_2nd_e_5    0.50958     0.63606  0.57282\n",
       "5    base_all_e_7    0.48374     0.61216  0.54795\n",
       "6    base_5th_e_5    0.51670     0.64624  0.58147\n",
       "7   large_all_e_9    0.52332     0.64678  0.58505\n",
       "8    large_v3_e_1    0.54694     0.67216  0.60955\n",
       "9    base_4th_e_5    0.51768     0.64680  0.58224\n",
       "10   large_v1_e_5    0.54804     0.67272  0.61038"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy = [\"concat\"]\n",
    "# embeds_to_score = [[\"base_5th_e_5\",\"large_v2_e_5\",\"large_v3_e_1\",\"large_v1_e_5\",\"large_v4_e_1\"]] + [i for c in range(2,6) for i in itertools.combinations([\"base_5th_e_5\",\"large_v2_e_5\",\"large_v3_e_1\",\"large_v1_e_5\",\"large_v4_e_1\"],c)]\n",
    "# embeds_to_score =[[\"base_5th_e_5\",\"large_v2_e_5\",\"large_v3_e_1\",\"large_v1_e_5\",\"large_v4_e_1\"]]\n",
    "embeds_to_score = [[key] for key in list(all_text_embed.keys())]\n",
    "score_df = pd.DataFrame()\n",
    "embeds_to_score_name = []\n",
    "top5_score = []\n",
    "top10_score = []\n",
    "avg_score = []\n",
    "for s in strategy:\n",
    "    for e in tqdm(embeds_to_score):\n",
    "        ensamsables = get_ensamble(all_image_embed,all_text_embed,e,s,[1,1,1,1,1])\n",
    "        top5_acc,top10_acc,avg_acc = get_preds(ensamsables,score=True,use_faiss=True,auto_faiss=False,max_ensamble=False,df=clean_df)\n",
    "        if len(e) == len(list(all_text_embed.keys())):\n",
    "            name = \"all models\"\n",
    "        elif len(e) >1 and  len(e) < len(list(all_text_embed.keys())):\n",
    "            name = \" + \".join(e)\n",
    "        else:\n",
    "            name = e[0]\n",
    "        embeds_to_score_name.append(name)\n",
    "        top5_score.append(top5_acc)\n",
    "        top10_score.append(top10_acc)\n",
    "        avg_score.append(avg_acc)\n",
    "score_df[\"model\"] = embeds_to_score_name\n",
    "score_df[\"top_5_acc\"] = top5_score\n",
    "score_df[\"top_10_acc\"] = top10_score\n",
    "score_df[\"avg_acc\"] = avg_score\n",
    "\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>top_5_acc</th>\n",
       "      <th>top_10_acc</th>\n",
       "      <th>avg_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large_v2_e_5</td>\n",
       "      <td>0.56708</td>\n",
       "      <td>0.69000</td>\n",
       "      <td>0.62854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>large_v4_e_1</td>\n",
       "      <td>0.54818</td>\n",
       "      <td>0.67414</td>\n",
       "      <td>0.61116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>large_v1_e_5</td>\n",
       "      <td>0.54804</td>\n",
       "      <td>0.67272</td>\n",
       "      <td>0.61038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>large_v3_e_1</td>\n",
       "      <td>0.54694</td>\n",
       "      <td>0.67216</td>\n",
       "      <td>0.60955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>large_all_e_9</td>\n",
       "      <td>0.52332</td>\n",
       "      <td>0.64678</td>\n",
       "      <td>0.58505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base_4th_e_5</td>\n",
       "      <td>0.51768</td>\n",
       "      <td>0.64680</td>\n",
       "      <td>0.58224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>base_5th_e_5</td>\n",
       "      <td>0.51670</td>\n",
       "      <td>0.64624</td>\n",
       "      <td>0.58147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base_2nd_e_5</td>\n",
       "      <td>0.50958</td>\n",
       "      <td>0.63606</td>\n",
       "      <td>0.57282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base_3rd_e_5</td>\n",
       "      <td>0.50848</td>\n",
       "      <td>0.63554</td>\n",
       "      <td>0.57201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base_1st_e_5</td>\n",
       "      <td>0.50582</td>\n",
       "      <td>0.63248</td>\n",
       "      <td>0.56915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base_all_e_7</td>\n",
       "      <td>0.48374</td>\n",
       "      <td>0.61216</td>\n",
       "      <td>0.54795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  top_5_acc  top_10_acc  avg_acc\n",
       "1    large_v2_e_5    0.56708     0.69000  0.62854\n",
       "0    large_v4_e_1    0.54818     0.67414  0.61116\n",
       "10   large_v1_e_5    0.54804     0.67272  0.61038\n",
       "8    large_v3_e_1    0.54694     0.67216  0.60955\n",
       "7   large_all_e_9    0.52332     0.64678  0.58505\n",
       "9    base_4th_e_5    0.51768     0.64680  0.58224\n",
       "6    base_5th_e_5    0.51670     0.64624  0.58147\n",
       "4    base_2nd_e_5    0.50958     0.63606  0.57282\n",
       "3    base_3rd_e_5    0.50848     0.63554  0.57201\n",
       "2    base_1st_e_5    0.50582     0.63248  0.56915\n",
       "5    base_all_e_7    0.48374     0.61216  0.54795"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.sort_values(\"avg_acc\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_df.to_csv(\"combination_results_8_6_22.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>top_5_acc</th>\n",
       "      <th>top_10_acc</th>\n",
       "      <th>avg_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>large_v2_e_5</td>\n",
       "      <td>0.56708</td>\n",
       "      <td>0.69000</td>\n",
       "      <td>0.62854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base_1st_e_5</td>\n",
       "      <td>0.50582</td>\n",
       "      <td>0.63248</td>\n",
       "      <td>0.56915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base_3rd_e_5</td>\n",
       "      <td>0.50848</td>\n",
       "      <td>0.63554</td>\n",
       "      <td>0.57201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base_2nd_e_5</td>\n",
       "      <td>0.50958</td>\n",
       "      <td>0.63606</td>\n",
       "      <td>0.57282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base_all_e_7</td>\n",
       "      <td>0.48374</td>\n",
       "      <td>0.61216</td>\n",
       "      <td>0.54795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  top_5_acc  top_10_acc  avg_acc\n",
       "0  large_v2_e_5    0.56708     0.69000  0.62854\n",
       "1  base_1st_e_5    0.50582     0.63248  0.56915\n",
       "2  base_3rd_e_5    0.50848     0.63554  0.57201\n",
       "3  base_2nd_e_5    0.50958     0.63606  0.57282\n",
       "4  base_all_e_7    0.48374     0.61216  0.54795"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.read_csv(\"combination_results_8_6_22.csv\")\n",
    "score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>top_5_acc</th>\n",
       "      <th>top_10_acc</th>\n",
       "      <th>avg_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>large_v2_e_5 + base_5th_e_5 + large_v1_e_5</td>\n",
       "      <td>0.59548</td>\n",
       "      <td>0.71570</td>\n",
       "      <td>0.65559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>large_v2_e_5 + base_2nd_e_5 + base_5th_e_5 + large_all_e_9 + large_v1_e_5</td>\n",
       "      <td>0.59438</td>\n",
       "      <td>0.71440</td>\n",
       "      <td>0.65439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>large_v2_e_5 + base_2nd_e_5 + base_5th_e_5 + large_v1_e_5</td>\n",
       "      <td>0.59270</td>\n",
       "      <td>0.71446</td>\n",
       "      <td>0.65358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>large_v2_e_5 + base_4th_e_5 + large_v1_e_5</td>\n",
       "      <td>0.59274</td>\n",
       "      <td>0.71330</td>\n",
       "      <td>0.65302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>large_v2_e_5 + base_5th_e_5 + large_all_e_9 + base_4th_e_5 + large_v1_e_5</td>\n",
       "      <td>0.59290</td>\n",
       "      <td>0.71256</td>\n",
       "      <td>0.65273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>large_v2_e_5 + base_2nd_e_5 + large_v1_e_5</td>\n",
       "      <td>0.59232</td>\n",
       "      <td>0.71256</td>\n",
       "      <td>0.65244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>large_v2_e_5 + base_5th_e_5 + large_all_e_9</td>\n",
       "      <td>0.59252</td>\n",
       "      <td>0.71184</td>\n",
       "      <td>0.65218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>large_v2_e_5 + base_1st_e_5 + base_5th_e_5 + large_all_e_9 + large_v1_e_5</td>\n",
       "      <td>0.59118</td>\n",
       "      <td>0.71182</td>\n",
       "      <td>0.65150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>large_v2_e_5 + base_2nd_e_5 + large_all_e_9 + base_4th_e_5 + large_v1_e_5</td>\n",
       "      <td>0.59152</td>\n",
       "      <td>0.71146</td>\n",
       "      <td>0.65149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>large_v2_e_5 + base_5th_e_5 + large_all_e_9 + large_v1_e_5</td>\n",
       "      <td>0.59166</td>\n",
       "      <td>0.71116</td>\n",
       "      <td>0.65141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         model  \\\n",
       "69                                  large_v2_e_5 + base_5th_e_5 + large_v1_e_5   \n",
       "317  large_v2_e_5 + base_2nd_e_5 + base_5th_e_5 + large_all_e_9 + large_v1_e_5   \n",
       "171                  large_v2_e_5 + base_2nd_e_5 + base_5th_e_5 + large_v1_e_5   \n",
       "72                                  large_v2_e_5 + base_4th_e_5 + large_v1_e_5   \n",
       "324  large_v2_e_5 + base_5th_e_5 + large_all_e_9 + base_4th_e_5 + large_v1_e_5   \n",
       "62                                  large_v2_e_5 + base_2nd_e_5 + large_v1_e_5   \n",
       "67                                 large_v2_e_5 + base_5th_e_5 + large_all_e_9   \n",
       "287  large_v2_e_5 + base_1st_e_5 + base_5th_e_5 + large_all_e_9 + large_v1_e_5   \n",
       "319  large_v2_e_5 + base_2nd_e_5 + large_all_e_9 + base_4th_e_5 + large_v1_e_5   \n",
       "182                 large_v2_e_5 + base_5th_e_5 + large_all_e_9 + large_v1_e_5   \n",
       "\n",
       "     top_5_acc  top_10_acc  avg_acc  \n",
       "69     0.59548     0.71570  0.65559  \n",
       "317    0.59438     0.71440  0.65439  \n",
       "171    0.59270     0.71446  0.65358  \n",
       "72     0.59274     0.71330  0.65302  \n",
       "324    0.59290     0.71256  0.65273  \n",
       "62     0.59232     0.71256  0.65244  \n",
       "67     0.59252     0.71184  0.65218  \n",
       "287    0.59118     0.71182  0.65150  \n",
       "319    0.59152     0.71146  0.65149  \n",
       "182    0.59166     0.71116  0.65141  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 400)\n",
    "\n",
    "score_df.sort_values(\"avg_acc\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = [\"max\"]\n",
    "# # embeds_to_score = [[key] for key in list(all_text_embed.keys())] + [i for c in range(2,9) for i in itertools.combinations(all_text_embed,c)]\n",
    "# embeds_to_score =[[\"base_4th_e_5\",\"large_v2_e_5\",\"large_v1_e_5\"]]\n",
    "# embeds_to_score_name = []\n",
    "# c = []\n",
    "# top10_preds = []\n",
    "# top10_preds_score = []\n",
    "\n",
    "# for s in strategy:\n",
    "#     for e in embeds_to_score:\n",
    "#         ensamsables = get_ensamble(all_image_embed,all_text_embed,e,s)\n",
    "#         top10_score,top10_acc = get_preds(ensamsables,score=False,use_faiss=False,max_ensamble=True,auto_faiss=False,df=clean_df)\n",
    "#         if len(e) == len(list(all_text_embed.keys())):\n",
    "#             name = \"all models\"\n",
    "#         elif len(e) >1 and  len(e) < len(list(all_text_embed.keys())):\n",
    "#             name = \" + \".join(e)\n",
    "#         else:\n",
    "#             name = e[0]\n",
    "#         embeds_to_score_name.append(name)\n",
    "#         top10_preds.append(top10_acc)\n",
    "#         top10_preds_score.append(top10_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top5_pred,top10_pred =remap_pred_to_name(top5_pred_idx,top10_pred_idx,clean_df[\"product\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def results_to_json(top5_pred,top10_pred,caption_array,result_dir,result_file_name):\n",
    "#     results = []\n",
    "#     for c,t5,t10 in tqdm(zip(caption_array,top5_pred,top10_pred)):\n",
    "#         result_dict = {}\n",
    "#         result_dict[\"caption\"] = c\n",
    "#         result_dict[\"top5\"] = t5\n",
    "#         result_dict[\"top10\"] = t10\n",
    "#         results.append(result_dict)\n",
    "#     print(\"checking results format\")\n",
    "#     print(results[0])\n",
    "#     with open(f\"{result_dir}/{result_file_name}.json\",\"w\") as results_file:\n",
    "#         json.dump(results,results_file)\n",
    "#     with open(f\"{result_dir}/{result_file_name}.json\",\"r\") as results_file:\n",
    "#         check_results = json.load(results_file)\n",
    "#     print(\"checking results format of saved file\")\n",
    "#     print(check_results[0])\n",
    "#     return check_results\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_result = results_to_json(top5_pred,top10_pred,clean_df[\"caption\"].values,\"./submissions\",\"test_val_ensamble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "caf1c2fcf97217de91eafa76b907d50f9ea378f5ffbee7f571142d119bb6a771"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
