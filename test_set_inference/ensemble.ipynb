{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/test_set_inference', '/home/ubuntu/anaconda3/lib/python39.zip', '/home/ubuntu/anaconda3/lib/python3.9', '/home/ubuntu/anaconda3/lib/python3.9/lib-dynload', '', '/home/ubuntu/anaconda3/lib/python3.9/site-packages', '/home/ubuntu/anaconda3/lib/python3.9/site-packages/locket-0.2.1-py3.9.egg', '/home/ubuntu/anaconda3/lib/python3.9/site-packages/IPython/extensions', '/home/ubuntu/.ipython']\n",
      "['..', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/test_set_inference', '/home/ubuntu/anaconda3/lib/python39.zip', '/home/ubuntu/anaconda3/lib/python3.9', '/home/ubuntu/anaconda3/lib/python3.9/lib-dynload', '', '/home/ubuntu/anaconda3/lib/python3.9/site-packages', '/home/ubuntu/anaconda3/lib/python3.9/site-packages/locket-0.2.1-py3.9.egg', '/home/ubuntu/anaconda3/lib/python3.9/site-packages/IPython/extensions', '/home/ubuntu/.ipython', '/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/model']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "print(sys.path)\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/model\")\n",
    "print(sys.path)\n",
    "import clip\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "from model.aliproduct_model import ALIPRODUCT_CLIP\n",
    "from model.aliproduct_blip_model import ALIPRODUCT_BLIP\n",
    "from model.dataset import ALIPRODUCT_DATASET,prepare_data\n",
    "from model.CONFIG import CONFIG\n",
    "import faiss\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>test_caption</th>\n",
       "      <th>test_imgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>feiyangg/LP Paragraph Style Electric Guitar Ti...</td>\n",
       "      <td>O1CN01r2RqZk1lJ4Sk2ZYaN_!!2200643934797.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Summer Lace White Shorts Pants Female Thin Ant...</td>\n",
       "      <td>O1CN01H0o2pi2HAtGC9rVWa_!!2206736519111.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>High-Quality Export 8MM with Adhesive Cork Cor...</td>\n",
       "      <td>O1CN01qeHW0Z1D3mRPfmNvM_!!161-0-lubanu.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LED Ceiling Living Room Bedroom Corridor Corri...</td>\n",
       "      <td>O1CN01phQoOe25ljjN1lpLO_!!3082327567.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Disposable Cotton Cotton Female Thin Water Fac...</td>\n",
       "      <td>O1CN01Dzpgpr2FxJsUzqAdE_!!2963188946.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       test_caption  \\\n",
       "0           0  feiyangg/LP Paragraph Style Electric Guitar Ti...   \n",
       "1           1  Summer Lace White Shorts Pants Female Thin Ant...   \n",
       "2           2  High-Quality Export 8MM with Adhesive Cork Cor...   \n",
       "3           3  LED Ceiling Living Room Bedroom Corridor Corri...   \n",
       "4           4  Disposable Cotton Cotton Female Thin Water Fac...   \n",
       "\n",
       "                                     test_imgs  \n",
       "0  O1CN01r2RqZk1lJ4Sk2ZYaN_!!2200643934797.jpg  \n",
       "1  O1CN01H0o2pi2HAtGC9rVWa_!!2206736519111.jpg  \n",
       "2   O1CN01qeHW0Z1D3mRPfmNvM_!!161-0-lubanu.jpg  \n",
       "3     O1CN01phQoOe25ljjN1lpLO_!!3082327567.jpg  \n",
       "4     O1CN01Dzpgpr2FxJsUzqAdE_!!2963188946.jpg  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.read_csv(\"/home/ubuntu/Desktop/CVPR 2022 AliProducts Challenge/code/test_set_inference/test.csv\")\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embed_path = \"./image_embeds\"\n",
    "text_embed_path = \"./text_embeds\"\n",
    "image_embed_files = os.listdir(image_embed_path)\n",
    "text_embed_files = os.listdir(text_embed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  6.21it/s]\n"
     ]
    }
   ],
   "source": [
    "all_image_embed ={}\n",
    "all_text_embed = {}\n",
    "for i,t in tqdm(zip(image_embed_files,text_embed_files)):\n",
    "    with open(f\"{image_embed_path}/{i}\",\"rb\") as img_file:\n",
    "        img_embed = pickle.load(img_file)\n",
    "        all_image_embed[img_embed[\"model_name\"]] = img_embed[\"embed\"]\n",
    "    with open(f\"{text_embed_path}/{t}\",\"rb\") as txt_file:\n",
    "        txt_embed = pickle.load(txt_file)\n",
    "        all_text_embed[txt_embed[\"model_name\"]] = txt_embed[\"embed\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_all_e_7', 'base_2nd_e_5', 'base_1st_e_5', 'large_all_e_9'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_image_embed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_1st_e_5', 'base_2nd_e_5', 'base_all_e_7', 'large_all_e_9'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_embed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_to_test = \"large_all_e_9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_to_ensamble = [\"base_1st_e_5\",\"base_2nd_e_5\"]\n",
    "\n",
    "embed_to_ensamble = list(all_text_embed.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_text_embed[\"base_all_e_7\"] = all_text_embed[\"base_all_e_7\"][0:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensamble(all_image_embed,all_text_embed,embeds_to_ensamble,ensamble_strategy):\n",
    "    ensamsables = {}\n",
    "    img_embed_list = []\n",
    "    text_embed_list = []\n",
    "    for model_name in embeds_to_ensamble:\n",
    "        img_embed_list.append(all_image_embed[model_name])\n",
    "        text_embed_list.append(all_text_embed[model_name])\n",
    "    if len(embeds_to_ensamble) > 1:\n",
    "        if ensamble_strategy ==\"concat\":\n",
    "            ensamsables[\"image\"] = torch.concat(img_embed_list,dim=1)\n",
    "            ensamsables[\"text\"] = torch.concat(text_embed_list,dim=1)\n",
    "        elif ensamble_strategy ==\"avg\":\n",
    "            ensamsables[\"image\"] = torch.mean(torch.stack(img_embed_list))\n",
    "            ensamsables[\"text\"] = torch.mean(torch.concat(text_embed_list))\n",
    "        return ensamsables\n",
    "    else:\n",
    "            ensamsables[\"image\"] = img_embed_list\n",
    "            ensamsables[\"text\"] = text_embed_list\n",
    "            return ensamsables\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamsables = get_ensamble(all_image_embed,all_text_embed,embed_to_ensamble,\"concat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ensamsables[\"text\"] @ ensamsables[\"image\"].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[1.7092, 1.7044, 1.7009,  ..., 1.6379, 1.6238, 1.6073],\n",
       "        [1.7183, 1.7036, 1.6723,  ..., 1.5285, 1.5083, 1.4777],\n",
       "        [1.5418, 1.4432, 1.3890,  ..., 1.3541, 1.3369, 1.3197],\n",
       "        ...,\n",
       "        [1.6374, 1.5221, 1.5073,  ..., 1.4549, 1.4521, 1.4498],\n",
       "        [1.7417, 1.6889, 1.6012,  ..., 1.4738, 1.4729, 1.4722],\n",
       "        [1.5887, 1.5627, 1.5051,  ..., 1.3952, 1.3920, 1.3840]]),\n",
       "indices=tensor([[27694, 40609, 47178,  ..., 46458, 42193, 34667],\n",
       "        [23383, 44309,  5591,  ..., 22510,   582, 28545],\n",
       "        [31777, 16947, 46953,  ..., 10273,  4198, 45215],\n",
       "        ...,\n",
       "        [24440, 42947, 43062,  ...,  8586,  8216, 26535],\n",
       "        [ 4278, 18451, 39630,  ..., 20235, 27915, 11201],\n",
       "        [43082, 35529,  6883,  ..., 14069, 42845, 27301]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_preds(ensamsables,score=False,df=None):\n",
    "    image_embed = ensamsables[\"image\"]\n",
    "    text_embed = ensamsables[\"text\"]\n",
    "    faiss_index = faiss.IndexFlatIP(image_embed.shape[1])\n",
    "    faiss_index.add(image_embed.numpy().astype(np.float32))\n",
    "    top5_k_e,top5_k_y_pred = faiss_index.search(text_embed.numpy().astype(np.float32),5)\n",
    "    top10_k_e,top10_k_y_pred = faiss_index.search(text_embed.numpy().astype(np.float32),10)\n",
    "    if score:\n",
    "        top5_preds = np.array([1 if y_true in y_pred else 0 for y_true,y_pred in zip(df.index.values,top5_k_y_pred)])\n",
    "        top10_preds = np.array([1 if y_true in y_pred else 0 for y_true,y_pred in zip(df.index.values,top10_k_y_pred)])\n",
    "        top5_acc = top5_preds[top5_preds ==1].shape[0] / top5_preds.shape[0]\n",
    "        print(f\"top_5 accuracy:{top5_acc}\")\n",
    "        top10_acc = top10_preds[top10_preds ==1].shape[0] / top10_preds.shape[0]\n",
    "        avg_acc = (top5_acc+top10_acc)/2\n",
    "        print(f\"top_5 accuracy:{top10_acc}\")\n",
    "        print(f\"avg accuracy:{avg_acc}\")\n",
    "        return top5_acc,top10_acc,avg_acc\n",
    "    else:\n",
    "        return top5_k_y_pred,top10_k_y_pred,top5_k_e,top10_k_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_pred_idx,top10_pred_idx,top5_k_e,top10_k_e = get_preds(ensamsables,score=False,df=clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.709192 , 1.7043643, 1.7009404, 1.6768483, 1.6623586, 1.6431701,\n",
       "       1.6427323, 1.637881 , 1.6237569, 1.6073489], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_k_e[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_pred_to_name(top5_pred_idx,top10_pred_idx,image_array):\n",
    "    top5_pred = [list(image_array[p]) for p in top5_pred_idx]\n",
    "    top10_pred =  [list(image_array[p]) for p in top10_pred_idx]\n",
    "    return top5_pred,top10_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_pred,top10_pred =remap_pred_to_name(top5_pred_idx,top10_pred_idx,clean_df[\"test_imgs\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_json(top5_pred,top10_pred,caption_array,result_dir,result_file_name):\n",
    "    results = []\n",
    "    for c,t5,t10 in tqdm(zip(caption_array,top5_pred,top10_pred)):\n",
    "        result_dict = {}\n",
    "        result_dict[\"caption\"] = c\n",
    "        result_dict[\"top5\"] = t5\n",
    "        result_dict[\"top10\"] = t10\n",
    "        results.append(result_dict)\n",
    "    print(\"checking results format\")\n",
    "    print(results[0])\n",
    "    with open(f\"{result_dir}/{result_file_name}.json\",\"w\") as results_file:\n",
    "        json.dump(results,results_file)\n",
    "    with open(f\"{result_dir}/{result_file_name}.json\",\"r\") as results_file:\n",
    "        check_results = json.load(results_file)\n",
    "    print(\"checking results format of saved file\")\n",
    "    print(check_results[-1])\n",
    "    return check_results\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:00, 909373.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking results format\n",
      "{'caption': 'feiyangg/LP Paragraph Style Electric Guitar Tiger Veneer Factory Direct Color Can Be Customized', 'top5': ['TB25xAzdCGI.eBjSspcXXcVjFXa_!!754885367.jpg', 'O1CN01Dj2czX1oWlFVAZ05k_!!2207737885233.jpg', 'O1CN011pW88rTaqfnNIi1_!!754885367.jpg', 'O1CN01S8ewME1m1UwiK89Pr_!!1973994894.jpg', 'O1CN01p912eO1lKuB1TiTl6_!!2207916444801.png'], 'top10': ['TB25xAzdCGI.eBjSspcXXcVjFXa_!!754885367.jpg', 'O1CN01Dj2czX1oWlFVAZ05k_!!2207737885233.jpg', 'O1CN011pW88rTaqfnNIi1_!!754885367.jpg', 'O1CN01S8ewME1m1UwiK89Pr_!!1973994894.jpg', 'O1CN01p912eO1lKuB1TiTl6_!!2207916444801.png', 'O1CN016zxVN01qPYIlq8the_!!0-item_pic.jpg', 'O1CN01ha825u1ctPVv8XwDP_!!2211470413658-0-picasso.jpg', 'O1CN01h0ZgaM1qPYIr3q9Cf_!!0-item_pic.jpg', 'O1CN01XJH6iU1lKuBgk0ndT_!!2207916444801.jpg', 'TB2lylSaQ.OyuJjSszhXXbZbVXa_!!20295181.jpg']}\n",
      "checking results format of saved file\n",
      "{'caption': 'mrs harmay foods Handmade Cantonese Barbecued Pork Bag 390g/Bag', 'top5': ['O1CN019zeHtc2BQ6VwvUSxE_!!2680068332.jpg', 'O1CN01472J632BQ6ioi13iS_!!2680068332.jpg', 'O1CN01tBoUtb2BQ6fzmLjAK_!!2680068332.jpg', 'O1CN01JpPlbE1CGm4tg9SoJ_!!0-item_pic.jpg', 'O1CN01aK0SJY2BQ6UpSTVgJ_!!2680068332.jpg'], 'top10': ['O1CN019zeHtc2BQ6VwvUSxE_!!2680068332.jpg', 'O1CN01472J632BQ6ioi13iS_!!2680068332.jpg', 'O1CN01tBoUtb2BQ6fzmLjAK_!!2680068332.jpg', 'O1CN01JpPlbE1CGm4tg9SoJ_!!0-item_pic.jpg', 'O1CN01aK0SJY2BQ6UpSTVgJ_!!2680068332.jpg', 'O1CN01Eu7xDm2BQ6e9Q3DyO_!!2680068332.jpg', 'O1CN01O7vDGt2BQ6dhNjIfD_!!2680068332.jpg', 'O1CN011jYp9o1sKAkg64xpx_!!263685747.jpg', 'O1CN01URO74R1LfoCIHAQ1z_!!2208747631327.jpg', 'O1CN013fg8UF2BQ6irOxAkX_!!2680068332.jpg']}\n"
     ]
    }
   ],
   "source": [
    "saved_result = results_to_json(top5_pred,top10_pred,clean_df[\"test_caption\"].values[0:20000],\"./submissions\",\"test_ensamble_all_3_6_22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saved_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'caption': 'feiyangg/LP Paragraph Style Electric Guitar Tiger Veneer Factory Direct Color Can Be Customized',\n",
       "  'top5': ['TB25xAzdCGI.eBjSspcXXcVjFXa_!!754885367.jpg',\n",
       "   'O1CN01Dj2czX1oWlFVAZ05k_!!2207737885233.jpg',\n",
       "   'O1CN011pW88rTaqfnNIi1_!!754885367.jpg',\n",
       "   'O1CN01S8ewME1m1UwiK89Pr_!!1973994894.jpg',\n",
       "   'O1CN01p912eO1lKuB1TiTl6_!!2207916444801.png'],\n",
       "  'top10': ['TB25xAzdCGI.eBjSspcXXcVjFXa_!!754885367.jpg',\n",
       "   'O1CN01Dj2czX1oWlFVAZ05k_!!2207737885233.jpg',\n",
       "   'O1CN011pW88rTaqfnNIi1_!!754885367.jpg',\n",
       "   'O1CN01S8ewME1m1UwiK89Pr_!!1973994894.jpg',\n",
       "   'O1CN01p912eO1lKuB1TiTl6_!!2207916444801.png',\n",
       "   'O1CN016zxVN01qPYIlq8the_!!0-item_pic.jpg',\n",
       "   'O1CN01ha825u1ctPVv8XwDP_!!2211470413658-0-picasso.jpg',\n",
       "   'O1CN01h0ZgaM1qPYIr3q9Cf_!!0-item_pic.jpg',\n",
       "   'O1CN01XJH6iU1lKuBgk0ndT_!!2207916444801.jpg',\n",
       "   'TB2lylSaQ.OyuJjSszhXXbZbVXa_!!20295181.jpg']}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_result[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27694, 40609, 47178, 28805, 35939],\n",
       "       [23383, 44309,  5591, 19321, 16976],\n",
       "       [31777, 16947, 46953, 34609, 14996],\n",
       "       ...,\n",
       "       [24440, 42947, 43062,  7107, 31868],\n",
       "       [ 4278, 18451, 39630, 12274, 20602],\n",
       "       [43082, 35529,  6883, 12174, 26153]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_pred_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "caf1c2fcf97217de91eafa76b907d50f9ea378f5ffbee7f571142d119bb6a771"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
